{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "077cadd8",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5260aab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   species  \n",
      "0        0  \n",
      "1        0  \n",
      "2        0  \n",
      "3        0  \n",
      "4        0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "# Add the species column\n",
    "df['species'] = iris.target\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed7988c",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98aa1b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Features and Labels\n",
    "X = df.drop('species', axis=1)\n",
    "y = df['species']\n",
    "\n",
    "# Splitting the data - 80% train, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c61c858",
   "metadata": {},
   "source": [
    "## Build and train the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "617e9307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 1.0\n",
      "Random Forest Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Decision Tree Model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest Model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, dt_predictions))\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e1cd14",
   "metadata": {},
   "source": [
    "## Feature importance comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fee69185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Feature  DT Importance  RF Importance\n",
      "0  sepal length (cm)       0.000000       0.076213\n",
      "1   sepal width (cm)       0.016670       0.028866\n",
      "2  petal length (cm)       0.906143       0.439660\n",
      "3   petal width (cm)       0.077186       0.455262\n"
     ]
    }
   ],
   "source": [
    "# Feature importances from both models\n",
    "dt_importances = dt_model.feature_importances_\n",
    "rf_importances = rf_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': iris.feature_names,\n",
    "    'DT Importance': dt_importances,\n",
    "    'RF Importance': rf_importances\n",
    "})\n",
    "\n",
    "print(feature_importances_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a409f4",
   "metadata": {},
   "source": [
    "The comparison of feature importances between Decision Trees and Random Forests can provide insights into how each model perceives the importance of the features. While both can highlight important features, the Random Forest's aggregated view might offer a more balanced perspective, especially if some features have interaction effects that a single Decision Tree might miss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ab98ea",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "If the primary concern is predictive accuracy and generalizability, and computational resources are not a constraint, a Random Forest model may be considered better.\n",
    "Interms of interpretability and computational efficiency, or if you're working with a relatively simple dataset where overfitting is not a major concern, a Decision Tree might be sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe3c0d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
